{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:15:42.159501Z",
     "start_time": "2024-10-18T15:15:42.140762Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader import load_raw, create_datasets, create_dataloaders\n",
    "from measures import quantile_loss, compute_intermittent_indicators, rho_risk\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14703fcd44dd6c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:15:48.170623Z",
     "start_time": "2024-10-18T15:15:42.161965Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = \"M5\"\n",
    "method = \"TreeQRs\"\n",
    "\n",
    "data_raw, data_info = load_raw(dataset_name, datasets_folder_path=os.path.join(\"..\",\"data\"))\n",
    "adi, cv2 = compute_intermittent_indicators(data_raw, data_info['h'])\n",
    "datasets = create_datasets(data_raw, data_info)\n",
    "\n",
    "max_lag = {\n",
    "    'carparts':44,\n",
    "    'OnlineRetail':56,\n",
    "    'Auto':16,\n",
    "    'RAF':45,\n",
    "    'M5':50\n",
    "}\n",
    "\n",
    "lags = np.arange(1,max_lag[dataset_name]) if dataset_name != \"M5\" else [1,2,3,4,5,6,7,8,9,10,15,20,25,30,50,80,100,150]\n",
    "lags = np.unique(np.sort(np.concatenate([lags, np.array([data_info['h']*data_info['w']])])))\n",
    "quantiles = np.array([0.5, 0.8, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e1f6af11688889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:15:58.181769Z",
     "start_time": "2024-10-18T15:15:48.181513Z"
    }
   },
   "outputs": [],
   "source": [
    "scale_factor = []\n",
    "for y in datasets['valid']:\n",
    "    y = np.array(y['target'])\n",
    "    demand_mask = np.where(y != 0)\n",
    "    scale_factor.append(np.mean(y[demand_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a93b9de2ac8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:41:45.765535Z",
     "start_time": "2024-10-18T15:15:58.192961Z"
    }
   },
   "outputs": [],
   "source": [
    "for lag in [112]:\n",
    "    print(lag)\n",
    "\n",
    "    model_folder_name = method+\"l\" + str(lag) + \"__\" + dataset_name\n",
    "    model_folder_path = os.path.join('tree-regression', model_folder_name)\n",
    "\n",
    "    # each series is lag-embedded into a matrix at the given AR order and these matrices are stacked together to create on big matrix\n",
    "    X = []\n",
    "    Y = []\n",
    "    Xtest = []\n",
    "    Ytest = []\n",
    "    for ts, sf in zip(datasets[\"valid\"], scale_factor):\n",
    "        ts = np.array(ts['target']) / sf\n",
    "        for t in range(lag, len(datasets['valid'][0]['target'])):\n",
    "            X.append(ts[t-lag:t])\n",
    "            Y.append(ts[t])\n",
    "        Xtest.append(ts[-lag:])\n",
    "    for ts in datasets[\"test\"]:\n",
    "        ts = np.array(ts['target'])\n",
    "        Ytest.append(ts[-data_info['h']:])\n",
    "            \n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    Xtest, actuals = np.array(Xtest), np.array(Ytest)\n",
    "\n",
    "    # a maximum of 1 mio samples for training\n",
    "    np.random.seed(42)\n",
    "    filter_max = np.random.choice(X.shape[0], size=min(X.shape[0], 1_000_000), replace=False)\n",
    "    Xsub = X[filter_max]\n",
    "    Ysub = Y[filter_max]\n",
    "\n",
    "    X_df = pd.DataFrame(Xsub, columns=[f'X{i}' for i in range(1, lag + 1)])\n",
    "    Y_series = pd.Series(Ysub, name='Y')\n",
    "    \n",
    "    split = int(X_df.shape[0]*0.85)\n",
    "    train_dataset = lgb.Dataset(X_df.iloc[:split], label=Y_series.iloc[:split])\n",
    "    valid_dataset = lgb.Dataset(X_df.iloc[split:], label=Y_series.iloc[split:], reference=train_dataset)\n",
    "    \n",
    "    models = {}\n",
    "    for q in quantiles:\n",
    "        models[q] = lgb.train(\n",
    "            params={\n",
    "                'objective': 'quantile',\n",
    "                'alpha': q,\n",
    "                'boosting': 'gbdt',\n",
    "                'learning_rate':0.1,\n",
    "                'num_leaves':31,\n",
    "                'force_row_wise':True,\n",
    "                'seed':42\n",
    "            },\n",
    "            num_boost_round=1000,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=[valid_dataset],\n",
    "            callbacks=[\n",
    "                lgb.log_evaluation(period=0, show_stdv=True),\n",
    "                lgb.early_stopping(stopping_rounds=20, first_metric_only=True, verbose=True)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    Xtest_ = Xtest\n",
    "    quantile_forecasts = np.empty(shape=(Xtest.shape[0], quantiles.size, data_info['h']))\n",
    "    for h in range(data_info['h']):\n",
    "        for qi, q in enumerate(quantiles):\n",
    "            quantile_forecasts[:,qi,h] = np.round(models[q].predict(Xtest_) * scale_factor)\n",
    "        Xtest_ = np.concatenate([Xtest_[:,1:lag], models[0.5].predict(Xtest_).reshape(-1,1)], axis=1)\n",
    "    \n",
    "    if not os.path.exists(path=model_folder_path):\n",
    "        os.makedirs(model_folder_path)\n",
    "    if lag==1: np.save(os.path.join(model_folder_path,\"actuals.npy\"), actuals)\n",
    "    np.save(os.path.join(model_folder_path,\"qforecasts.npy\"), quantile_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c17a68d98d3c48f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:41:45.859637Z",
     "start_time": "2024-10-18T15:41:45.819916Z"
    }
   },
   "outputs": [],
   "source": [
    "subset=\"intermittent_and_lumpy\"\n",
    "if subset == \"intermittent\":\n",
    "    filter, filter_label = np.logical_and(adi >= 1.32, cv2 < .49), \"intermittent\"\n",
    "elif subset == \"intermittent_and_lumpy\":\n",
    "    filter, filter_label = adi >= 1.32, \"intermittent_and_lumpy\"\n",
    "elif subset == \"all\":\n",
    "    filter, filter_label = np.tile(True, adi.size), \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f523181eee2581a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:42:13.651988Z",
     "start_time": "2024-10-18T15:41:45.869492Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = np.empty(shape=(len(datasets['test']), len(datasets['valid'][0]['target']), quantiles.size))\n",
    "for i in range(len(datasets['test'])):\n",
    "    tmp[i, :] = np.round(np.quantile(datasets['valid'][i]['target'], q=quantiles))\n",
    "res_base_scale_tmp = []\n",
    "for i in range(len(datasets['test'])):\n",
    "    res_base_scale_tmp.append(quantile_loss(\n",
    "        np.array(datasets['valid'][i]['target']).reshape(1,-1), \n",
    "        tmp[i].reshape(1,tmp[i].shape[0],tmp[i].shape[1]), \n",
    "        quantiles, avg=False))\n",
    "res_base_scale = {}\n",
    "for q in ['QL50','QL80','QL90','QL95','QL99']:\n",
    "    res_base_scale[q] = np.mean(np.vstack([res_base_scale_tmp[i][q] for i in range(len(datasets['test']))]), axis=1)\n",
    "\n",
    "scale = True\n",
    "fscale = lambda x, q: x / res_base_scale[q][filter, np.newaxis] if scale else x\n",
    "\n",
    "path = os.path.join(\"tree-regression\")\n",
    "names = [folder for folder in os.listdir(path) \n",
    "                  if os.path.isdir(os.path.join(path, folder))]\n",
    "names_sub = [x for x in names if (x.split('__')[1] == dataset_name) and (x.split('__')[0].split('l')[0] == method)]\n",
    "M = {}\n",
    "actuals = np.load(os.path.join(path, method+'l1__'+dataset_name, \"actuals.npy\"))[filter]\n",
    "for n in names_sub:\n",
    "    quantile_forecasts = np.load(os.path.join(path, n, \"qforecasts.npy\"))[filter]\n",
    "    M[int(n.split('l')[1].split('__')[0])] = quantile_loss(actuals, np.transpose(quantile_forecasts, (0,2,1)), quantiles, avg=False)\n",
    "M = {key: M[key] for key in sorted(M.keys())}\n",
    "\n",
    "for k in M.keys():\n",
    "    for l in M[k].keys():\n",
    "        M[k][l] = fscale(M[k][l], l)\n",
    "\n",
    "# Local methods\n",
    "baseline_path = os.path.join(os.path.expanduser(\"~/switchdrive\"), \"iTS\", \"trained_models_baselines\")\n",
    "baselines_name = [folder for folder in os.listdir(baseline_path) \n",
    "                  if os.path.isdir(os.path.join(baseline_path, folder)) and os.path.exists(os.path.join(baseline_path, folder, 'metrics.json'))]\n",
    "baselines_name_sub = [x for x in baselines_name if x.split('__')[1] == dataset_name]\n",
    "\n",
    "iETS_actuals = np.load(os.path.join(baseline_path, np.array(baselines_name_sub)[[\"iETS\" in x for x in baselines_name_sub]][0], \"actuals.npy\"))[filter]\n",
    "iETS_quantile_forecasts = np.load(os.path.join(baseline_path, np.array(baselines_name_sub)[[\"iETS\" in x for x in baselines_name_sub]][0], \"qforecasts.npy\"))[filter]\n",
    "iETS = quantile_loss(iETS_actuals, iETS_quantile_forecasts, quantiles, avg=False)\n",
    "EmpQ_actuals = np.load(os.path.join(baseline_path, np.array(baselines_name_sub)[[\"EmpQ\" in x for x in baselines_name_sub]][0], \"actuals.npy\"))[filter]\n",
    "EmpQ_quantile_forecasts = np.load(os.path.join(baseline_path, np.array(baselines_name_sub)[[\"EmpQ\" in x for x in baselines_name_sub]][0], \"qforecasts.npy\"))[filter]\n",
    "EmpQ = quantile_loss(EmpQ_actuals, EmpQ_quantile_forecasts, quantiles, avg=False)\n",
    "\n",
    "assert iETS.keys() == EmpQ.keys()\n",
    "for k in iETS.keys():\n",
    "    iETS[k] = fscale(iETS[k],k)\n",
    "    EmpQ[k] = fscale(EmpQ[k],k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf51c34e1d7da1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:42:14.561603Z",
     "start_time": "2024-10-18T15:42:13.670477Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(M, open(os.path.join('cache_global', method+'_'+dataset_name+\".pkl\"), 'wb'))\n",
    "pkl.dump(iETS, open(os.path.join('cache_global', \"iETS\"+'_'+dataset_name+\".pkl\"), 'wb'))\n",
    "pkl.dump(EmpQ, open(os.path.join('cache_global', \"EmpQ\"+'_'+dataset_name+\".pkl\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b599bfdfacc37a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:42:14.807571Z",
     "start_time": "2024-10-18T15:42:14.574002Z"
    }
   },
   "outputs": [],
   "source": [
    "Q = list(M[lags[0]].keys())\n",
    "fig, axs = plt.subplots(1,len(Q), figsize=(10,5), sharey=True)\n",
    "colors = ['#87CEFA','#00BFFF','#1E90FF','#4682B4','#191970']\n",
    "for ax, c, q_ in zip(axs, colors, Q):\n",
    "    tmp = [np.mean(M[l][q_]) for l in lags]\n",
    "    ax.hlines(y=np.mean(EmpQ[q_]), xmin=1, xmax=lags[-1], color=c, linestyle=':', label=\"EmpQ\")\n",
    "    ax.hlines(y=np.mean(iETS[q_]), xmin=1, xmax=lags[-1], color=c, linestyle='--', label=\"iETS\")\n",
    "    ax.plot(lags, tmp, color=c, label=\"TreeQR\")\n",
    "    ax.set_title(q_)\n",
    "axs[2].set_xlabel('LAG')\n",
    "axs[0].set_ylabel('QL')\n",
    "axs[-1].legend(loc=\"upper right\")\n",
    "plt.suptitle(dataset_name)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7bf9ea3ae0b02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T15:42:14.820631Z",
     "start_time": "2024-10-18T15:42:14.819208Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "its",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
