{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dataloader import load_raw, create_datasets\n",
    "from measures import quantile_loss_sample, compute_intermittent_indicators\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"/Users/nicolo.rubattu/switchdrive/iTS/trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = np.load(os.path.join(path, \"transformer__M5__tweedie__mean-demand__2024-07-01-08-37-15-418404/actuals.npy\"))\n",
    "forecasts_negbin = np.load(os.path.join(path, \"transformer__M5__negbin__mean-demand__2024-06-30-03-26-19-805850/forecasts.npy\"))\n",
    "forecasts_tweedie = np.load(os.path.join(path, \"transformer__M5__tweedie__mean-demand__2024-07-01-08-37-15-418404/forecasts.npy\"))\n",
    "\n",
    "actuals.shape, forecasts_negbin.shape, forecasts_tweedie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecasts(i, ts, back=14, r=3):\n",
    "    _, axs = plt.subplots(2,14, figsize=(20,4), sharey=True)\n",
    "    for h, ax in enumerate(axs.flatten()):\n",
    "        ax.hist(np.round(forecasts_negbin[i,:,h]), color=\"tab:orange\", bins=int(max(np.unique(np.round(forecasts_negbin[i,:,0])).size, np.unique(np.round(forecasts_tweedie[i,:,0])).size)/r), alpha=0.5)\n",
    "        ax.hist(np.round(forecasts_tweedie[i,:,h]), color=\"m\", bins=int(max(np.unique(np.round(forecasts_negbin[i,:,0])).size,np.unique(np.round(forecasts_tweedie[i,:,0])).size)/r), alpha=0.5)\n",
    "        ax.text(actuals[i,h], -.5, \"â–²\")\n",
    "        ax.set_xlabel(\"h=\"+str(h+1))\n",
    "        # ax.get_yaxis().set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        # ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        plt.suptitle(\"Forecast densities (i=\"+str(i)+\")\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    _, axs = plt.subplots(1,2, figsize=(20,4), sharey=True, sharex=True)\n",
    "    axs[0].plot(np.append(ts[-back:], actuals[i]), color=\"black\", label=\"y\")\n",
    "    axs[0].plot(np.arange(back,28+back), [np.quantile(x, 0.5) for x in forecasts_negbin[i,:].T], color=\"tab:orange\", label=\"yhat\")\n",
    "    axs[0].plot(np.linspace(back-1,back), np.linspace(ts[-back:][-1], np.quantile(forecasts_negbin[i,:,0], 0.5)), color=\"tab:orange\")\n",
    "    axs[0].fill_between(np.arange(back,28+back), np.tile(0,28), [np.quantile(x, 0.50) for x in forecasts_negbin[i,:].T], color=\"tab:orange\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[0].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.quantile(forecasts_negbin[i,:,0], 0.5)), color=\"tab:orange\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[0].text(back+27.2, np.round(np.quantile(forecasts_negbin[i,:,-1], 0.50)), \"QL50\", fontsize=8)\n",
    "    axs[0].fill_between(np.arange(back,28+back), np.tile(0,28), [np.quantile(x, 0.80) for x in forecasts_negbin[i,:].T], color=\"tab:orange\", alpha=0.1, label=\"QL80\", edgecolor=\"none\")\n",
    "    axs[0].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.quantile(forecasts_negbin[i,:,0], 0.8)), color=\"tab:orange\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[0].text(back+27.2, np.round(np.quantile(forecasts_negbin[i,:,-1], 0.80)), \"QL80\", fontsize=8)\n",
    "    axs[0].fill_between(np.arange(back,28+back), np.tile(0,28), [np.quantile(x, 0.90) for x in forecasts_negbin[i,:].T], color=\"tab:orange\", alpha=0.1, label=\"QL90\", edgecolor=\"none\")\n",
    "    axs[0].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.quantile(forecasts_negbin[i,:,0], 0.9)), color=\"tab:orange\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[0].text(back+27.2, np.round(np.quantile(forecasts_negbin[i,:,-1], 0.90)), \"QL90\", fontsize=8)\n",
    "    axs[0].fill_between(np.arange(back,28+back), np.tile(0,28), [np.quantile(x, 0.95) for x in forecasts_negbin[i,:].T], color=\"tab:orange\", alpha=0.1, label=\"QL95\", edgecolor=\"none\")\n",
    "    axs[0].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.quantile(forecasts_negbin[i,:,0], 0.95)), color=\"tab:orange\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[0].text(back+27.2, np.round(np.quantile(forecasts_negbin[i,:,-1], 0.95)), \"QL95\", fontsize=8)\n",
    "    axs[0].fill_between(np.arange(back,28+back), np.tile(0,28), [np.quantile(x, 0.99) for x in forecasts_negbin[i,:].T], color=\"tab:orange\", alpha=0.1, label=\"QL99\", edgecolor=\"none\")\n",
    "    axs[0].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.quantile(forecasts_negbin[i,:,0], 0.99)), color=\"tab:orange\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[0].text(back+27.2, np.round(np.quantile(forecasts_negbin[i,:,-1], 0.99)), \"QL99\", fontsize=8)\n",
    "    axs[0].set_title(\"negbin (i=\"+str(i)+\")\")\n",
    "    axs[0].set_xticks(range(back+28))\n",
    "    axs[0].set_xticklabels(back*[\"\"] + [str(x) for x in list(range(1,29))])\n",
    "\n",
    "    axs[1].plot(np.append(ts[-back:], actuals[i]), color=\"black\", label=\"y\")\n",
    "    axs[1].plot(np.arange(back,28+back), [np.round(np.quantile(x, 0.5)) for x in forecasts_tweedie[i,:].T], color=\"m\", label=\"yhat\")\n",
    "    axs[1].plot(np.linspace(back-1,back), np.linspace(ts[-back:][-1], np.round(np.quantile(forecasts_tweedie[i,:,0], 0.5))), color=\"m\")\n",
    "    axs[1].fill_between(np.arange(back,28+back), np.tile(0,28), [np.round(np.quantile(x, 0.50)) for x in forecasts_tweedie[i,:].T], color=\"m\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[1].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.round(np.quantile(forecasts_tweedie[i,:,0], 0.5))), color=\"m\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[1].text(back+27.2, np.round(np.quantile(forecasts_tweedie[i,:,-1], 0.50)), \"QL50\", fontsize=8)\n",
    "    axs[1].fill_between(np.arange(back,28+back), np.tile(0,28), [np.round(np.quantile(x, 0.80)) for x in forecasts_tweedie[i,:].T], color=\"m\", alpha=0.1, label=\"QL80\", edgecolor=\"none\")\n",
    "    axs[1].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.round(np.quantile(forecasts_tweedie[i,:,0], 0.8))), color=\"m\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[1].text(back+27.2, np.round(np.quantile(forecasts_tweedie[i,:,-1], 0.80)), \"QL80\", fontsize=8)\n",
    "    axs[1].fill_between(np.arange(back,28+back), np.tile(0,28), [np.round(np.quantile(x, 0.90)) for x in forecasts_tweedie[i,:].T], color=\"m\", alpha=0.1, label=\"QL90\", edgecolor=\"none\")\n",
    "    axs[1].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.round(np.quantile(forecasts_tweedie[i,:,0], 0.9))), color=\"m\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[1].text(back+27.2, np.round(np.quantile(forecasts_tweedie[i,:,-1], 0.90)), \"QL90\", fontsize=8)\n",
    "    axs[1].fill_between(np.arange(back,28+back), np.tile(0,28), [np.round(np.quantile(x, 0.95)) for x in forecasts_tweedie[i,:].T], color=\"m\", alpha=0.1, label=\"QL95\", edgecolor=\"none\")\n",
    "    axs[1].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.round(np.quantile(forecasts_tweedie[i,:,0], 0.95))), color=\"m\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[1].text(back+27.2, np.round(np.quantile(forecasts_tweedie[i,:,-1], 0.95)), \"QL95\", fontsize=8)\n",
    "    axs[1].fill_between(np.arange(back,28+back), np.tile(0,28), [np.round(np.quantile(x, 0.99)) for x in forecasts_tweedie[i,:].T], color=\"m\", alpha=0.1, label=\"QL99\", edgecolor=\"none\")\n",
    "    axs[1].fill_between(np.linspace(back-1,back), np.tile(0,50), np.linspace(ts[-back:][-1], np.round(np.quantile(forecasts_tweedie[i,:,0], 0.99))), color=\"m\", alpha=0.1, label=\"QL50\", edgecolor=\"none\")\n",
    "    axs[1].text(back+27.2, np.round(np.quantile(forecasts_tweedie[i,:,-1], 0.99)), \"QL99\", fontsize=8)\n",
    "    axs[1].set_title(\"tweedie (i=\"+str(i)+\")\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.arange(0,1,0.025)\n",
    "quantiles = np.append(quantiles, 0.99)\n",
    "coverage = []\n",
    "for samples, a in tqdm(zip(forecasts_negbin, actuals), total=forecasts_negbin.shape[0]):\n",
    "    for samples_h, a_h in zip(samples.T, a):\n",
    "        # if a_h == 0: continue\n",
    "        coverage.append(a_h <= np.quantile(samples_h, quantiles))\n",
    "coverage = np.stack(coverage)\n",
    "predicted_quantiles_negbin = np.round(np.mean(coverage, axis=0), 3)\n",
    "coverage = []\n",
    "for samples, a in tqdm(zip(forecasts_tweedie, actuals), total=forecasts_tweedie.shape[0]):\n",
    "    for samples_h, a_h in zip(samples.T, a):\n",
    "        # if a_h == 0: continue\n",
    "        coverage.append(a_h <= np.round(np.quantile(samples_h, quantiles)))\n",
    "coverage = np.stack(coverage)\n",
    "predicted_quantiles_tweedie = np.round(np.mean(coverage, axis=0), 3)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(quantiles, quantiles, color=\"black\")\n",
    "# plt.scatter(quantiles, quantiles, color=\"black\", s=12, lw=1)\n",
    "plt.plot(quantiles, predicted_quantiles_negbin, label=\"negbin\", color=\"tab:orange\")\n",
    "plt.scatter(quantiles, predicted_quantiles_negbin, color=\"tab:orange\", s=12)\n",
    "for x, y in zip(quantiles, predicted_quantiles_negbin):\n",
    "    plt.hlines(y, xmin=quantiles[0], xmax=x, colors='tab:orange', linestyles='dashed', alpha=0.5, lw=0.3)\n",
    "plt.plot(quantiles, predicted_quantiles_tweedie, label=\"tweedie\", color=\"m\")\n",
    "plt.scatter(quantiles, predicted_quantiles_tweedie, color=\"m\", s=12)\n",
    "for x, y in zip(quantiles, predicted_quantiles_tweedie):\n",
    "    plt.hlines(y, xmin=quantiles[0], xmax=x, colors='m', linestyles='dashed', alpha=0.5, lw=0.3)    \n",
    "    \n",
    "plt.axhline(np.mean(actuals==0), ls='dashed', c=\"gray\", label=\"proportion of zeros\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Coverage')\n",
    "plt.xlabel('quantiles')\n",
    "plt.xticks(np.round(quantiles,3), fontsize=8, rotation=90)\n",
    "plt.ylabel('coverage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.arange(0,1,0.025)\n",
    "quantiles = np.append(quantiles, 0.99)\n",
    "coverage = []\n",
    "for samples, a in tqdm(zip(forecasts_negbin, actuals), total=forecasts_negbin.shape[0]):\n",
    "    for samples_h, a_h in zip(samples.T, a):\n",
    "        if a_h == 0: continue\n",
    "        coverage.append(a_h <= np.quantile(samples_h, quantiles))\n",
    "coverage = np.stack(coverage)\n",
    "predicted_quantiles_negbin = np.round(np.mean(coverage, axis=0), 3)\n",
    "coverage = []\n",
    "for samples, a in tqdm(zip(forecasts_tweedie, actuals), total=forecasts_tweedie.shape[0]):\n",
    "    for samples_h, a_h in zip(samples.T, a):\n",
    "        if a_h == 0: continue\n",
    "        coverage.append(a_h <= np.round(np.quantile(samples_h, quantiles)))\n",
    "coverage = np.stack(coverage)\n",
    "predicted_quantiles_tweedie = np.round(np.mean(coverage, axis=0), 3)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(quantiles, quantiles, color=\"black\")\n",
    "# plt.scatter(quantiles, quantiles, color=\"black\", s=12, lw=1)\n",
    "plt.plot(quantiles, predicted_quantiles_negbin, label=\"negbin\", color=\"tab:orange\")\n",
    "plt.scatter(quantiles, predicted_quantiles_negbin, color=\"tab:orange\", s=12)\n",
    "for x, y in zip(quantiles, predicted_quantiles_negbin):\n",
    "    plt.hlines(y, xmin=quantiles[0], xmax=x, colors='tab:orange', linestyles='dashed', alpha=0.5, lw=0.3)\n",
    "plt.plot(quantiles, predicted_quantiles_tweedie, label=\"tweedie\", color=\"m\")\n",
    "plt.scatter(quantiles, predicted_quantiles_tweedie, color=\"m\", s=12)\n",
    "for x, y in zip(quantiles, predicted_quantiles_tweedie):\n",
    "    plt.hlines(y, xmin=quantiles[0], xmax=x, colors='m', linestyles='dashed', alpha=0.5, lw=0.3)    \n",
    "    \n",
    "plt.axhline(np.mean(actuals==0), ls='dashed', c=\"gray\", label=\"proportion of zeros\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Coverage of demand')\n",
    "plt.xlabel('quantiles')\n",
    "plt.xticks(np.round(quantiles,3), fontsize=8, rotation=90)\n",
    "plt.ylabel('coverage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw, data_info = load_raw(dataset_name='M5', datasets_folder_path=os.path.join(\"..\", \"data\"))\n",
    "datasets = create_datasets(data_raw, data_info)\n",
    "adi, cv2 = compute_intermittent_indicators(data_raw, data_info['h'])\n",
    "intermittent_mask = np.logical_and(adi >= 1.32, cv2 <= 0.49)\n",
    "\n",
    "ql_negbin = quantile_loss_sample(actuals, forecasts_negbin, avg=False)\n",
    "ql_tweedie = quantile_loss_sample(actuals, forecasts_tweedie, avg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (np.mean(ql_negbin['QL90'], axis=1) - np.mean(ql_tweedie['QL90'], axis=1))\n",
    "tmp_i = np.arange(200,210,1)\n",
    "print(\"negbin is way better\\t\",   [(a,b) for a,b in zip(np.argsort(tmp)[tmp_i], intermittent_mask[np.argsort(tmp)[tmp_i]])])\n",
    "print(\"tweedie is way better\\t\",  [(a,b) for a,b in zip(np.argsort(tmp)[::-1][tmp_i], intermittent_mask[np.argsort(tmp)[tmp_i]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11687\n",
    "plot_forecasts(i, back=100, ts=np.array(datasets['test'][i]['target'])[:-data_info['h']], r=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from measures import quantile_loss\n",
    "\n",
    "baseline_path = os.path.join(os.path.expanduser(\"~/switchdrive\"), \"iTS\", \"trained_models_baselines\")\n",
    "baselines_name = [folder for folder in os.listdir(baseline_path) \n",
    "                  if os.path.isdir(os.path.join(baseline_path, folder)) and os.path.exists(os.path.join(baseline_path, folder, 'metrics.json'))]\n",
    "baselines_name_sub = [x for x in baselines_name if x.split('__')[1] == \"M5\"]\n",
    "\n",
    "subset=\"intermittent\"\n",
    "if subset == \"intermittent\":\n",
    "    filter, filter_label = np.logical_and(adi >= 1.32, cv2 < .49), \"intermittent\"\n",
    "elif subset == \"intermittent_and_lumpy\":\n",
    "    filter, filter_label = adi >= 1.32, \"intermittent_and_lumpy\"\n",
    "elif subset == \"all\":\n",
    "    filter, filter_label = np.tile(True, adi.size), \"all\"\n",
    "\n",
    "quantiles = [0.5,0.8,0.9,0.95, 0.99]\n",
    "tmp = np.empty(shape=(len(datasets['test']), len(datasets['valid'][0]['target']), len(quantiles)))\n",
    "for i in range(len(datasets['test'])):\n",
    "    tmp[i, :] = np.round(np.quantile(datasets['valid'][i]['target'], q=quantiles))\n",
    "res_base_scale_tmp = []\n",
    "for i in range(len(datasets['test'])):\n",
    "    res_base_scale_tmp.append(quantile_loss(np.array(datasets['valid'][i]['target']).reshape(1,-1), tmp[i].reshape(1,tmp[i].shape[0],tmp[i].shape[1]), quantiles, avg=False))\n",
    "res_base_scale = {}\n",
    "for q in ['QL50','QL80','QL90','QL95','QL99']:\n",
    "    res_base_scale[q] = np.mean(np.vstack([res_base_scale_tmp[i][q] for i in range(len(datasets['test']))]), axis=1)[filter]\n",
    "\n",
    "aggf=np.mean\n",
    "scale=True\n",
    "fscale = lambda x, q: x / res_base_scale[q][:, np.newaxis] if scale else x\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(16,3))\n",
    "plt.suptitle(\"Agg. scaled quantile loss\")\n",
    "for q, ax in zip(['QL50','QL80','QL90','QL95','QL99'], axs):\n",
    "    ax.set_title(q)\n",
    "    ax.set_xlabel('h')\n",
    "    ax.plot(np.mean(fscale(ql_negbin[q][filter], q), axis=0), color=\"tab:orange\")\n",
    "    ax.text(27.5, np.mean(fscale(ql_negbin[q][filter], q), axis=0)[-1],\"negbin\", color=\"tab:orange\")\n",
    "for q, ax in zip(['QL50','QL80','QL90','QL95','QL99'], axs):\n",
    "    ax.plot(np.mean(fscale(ql_tweedie[q][filter], q), axis=0), color=\"m\")\n",
    "    ax.text(27.5, np.mean(fscale(ql_tweedie[q][filter], q), axis=0)[-1],\"tweedie\", color=\"m\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=\"intermittent\"\n",
    "if subset == \"intermittent\":\n",
    "    filter, filter_label = np.logical_and(adi >= 1.32, cv2 < .49), \"intermittent\"\n",
    "elif subset == \"intermittent_and_lumpy\":\n",
    "    filter, filter_label = adi >= 1.32, \"intermittent_and_lumpy\"\n",
    "elif subset == \"all\":\n",
    "    filter, filter_label = np.tile(True, adi.size), \"all\"\n",
    "\n",
    "for q in ['QL50','QL80','QL90','QL95','QL99']:\n",
    "    res_base_scale[q] = np.mean(np.vstack([res_base_scale_tmp[i][q] for i in range(len(datasets['test']))]), axis=1)\n",
    "    \n",
    "fscale = lambda x, q: x / res_base_scale[q][:, np.newaxis]\n",
    "\n",
    "for q in ql_negbin.keys():\n",
    "    print(q)\n",
    "    print('   negbin zero  \\t', np.round(np.sum(fscale(ql_negbin[q],q)[filter][actuals[filter]==0]),2))\n",
    "    print('   negbin demand\\t', np.round(np.sum(fscale(ql_negbin[q],q)[filter][actuals[filter]!=0]),2))\n",
    "    print('   tweedie zero  \\t', np.round(np.sum(fscale(ql_tweedie[q],q)[filter][actuals[filter]==0]),2))\n",
    "    print('   tweedie demand\\t', np.round(np.sum(fscale(ql_tweedie[q],q)[filter][actuals[filter]!=0]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=\"intermittent_and_lumpy\"\n",
    "if subset == \"intermittent\":\n",
    "    filter, filter_label = np.logical_and(adi >= 1.32, cv2 < .49), \"intermittent\"\n",
    "elif subset == \"intermittent_and_lumpy\":\n",
    "    filter, filter_label = adi >= 1.32, \"intermittent_and_lumpy\"\n",
    "elif subset == \"all\":\n",
    "    filter, filter_label = np.tile(True, adi.size), \"all\"\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(16,4), sharey=True)\n",
    "for ax, q in zip(axs, ql_negbin.keys()):\n",
    "    box = (ql_negbin[q] > ql_tweedie[q])*2\n",
    "    box[ql_tweedie[q] == ql_negbin[q]] = 1\n",
    "    ax.imshow(box[filter], vmin=0, vmax=2, cmap=\"bwr\", aspect='auto')\n",
    "    ax.set_title(q)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(DSET, MODEL=\"deepAR\", s=3, alpha=0.1):        \n",
    "    entries = os.listdir(path)\n",
    "    directories = [entry for entry in entries if os.path.isdir(os.path.join(path, entry))]\n",
    "    directories_M5Trans = [entry for entry in directories if DSET in entry and MODEL in entry]\n",
    "\n",
    "    data_raw, data_info = load_raw(dataset_name=DSET, datasets_folder_path=os.path.join(\"..\", \"data\"))\n",
    "    adi, cv2 = compute_intermittent_indicators(data_raw, data_info['h'])\n",
    "    datasets = create_datasets(data_raw, data_info)\n",
    "\n",
    "    context_width = data_info['h'] * data_info['w']\n",
    "\n",
    "    res = []\n",
    "    for m in ['negbin','tweedie']:\n",
    "        directories_M5Trans_m = [entry for entry in directories_M5Trans if \"__\"+m+\"__\" in entry]\n",
    "        for d in directories_M5Trans_m:\n",
    "            actuals = np.load(os.path.join(path, d, \"actuals.npy\"))\n",
    "            forecasts = np.load(os.path.join(path, d, \"forecasts.npy\"))\n",
    "            ql = quantile_loss_sample(actuals, forecasts, quantiles=[0.5, 0.8, 0.9, 0.95, 0.99], avg=False)\n",
    "            res.append( (m, actuals, ql) )\n",
    "    res_df0 = pd.DataFrame(res, columns=['distr', 'actuals','quantile_loss'])\n",
    "\n",
    "    actuals = res_df0.actuals.values[0]\n",
    "    res = []\n",
    "    for m in ['negbin','tweedie']:\n",
    "        res_df_m = res_df0[res_df0.distr == m].quantile_loss.values\n",
    "        for q in res_df_m[0].keys():\n",
    "            ql_avg = np.mean(np.stack([x[q] for x in res_df_m]), axis=0)\n",
    "            res.append( (m, q, ql_avg) )\n",
    "    res_df = pd.DataFrame(res, columns=['distr', 'q','quantile_loss'])\n",
    "\n",
    "    comb = []\n",
    "    for i in range(len(datasets['test'])):\n",
    "        a = actuals[i]\n",
    "        for q in res_df.q.unique():\n",
    "            ql_negbin = res_df[(res_df.distr==\"negbin\") & (res_df.q==q)].quantile_loss.values[0][i]\n",
    "            ql_tweedie = res_df[(res_df.distr==\"tweedie\") & (res_df.q==q)].quantile_loss.values[0][i]\n",
    "            condw = np.array(datasets['test'][i]['target'][:-data_info['h']][-context_width:])\n",
    "            cond_ts = np.array(datasets['test'][i]['target'][:-data_info['h']])\n",
    "            comb.append( (a, q, \n",
    "                        np.mean(ql_negbin), np.mean(ql_tweedie), \n",
    "                        adi[i], cv2[i], \n",
    "                        np.mean(condw), np.median(condw), \n",
    "                        np.mean(condw==0), np.median(condw[condw>0]) if np.sum(condw>0) else 1,\n",
    "                        np.mean(cond_ts[cond_ts>0])) )\n",
    "    comb = pd.DataFrame(comb, columns=['actual', 'q','ql_negbin', 'ql_tweedie', 'adi', 'cv2', 'condw_mean', 'condw_median', 'condw_0s', 'condw_meand', 'ts_meand'])\n",
    "\n",
    "    def target_f(n,t):\n",
    "        if n < t: return(-1)    # negbin wins\n",
    "        if n == t: return(0)    # tie\n",
    "        if n > t: return(1)     # tweedie wins\n",
    "\n",
    "    comb['target'] = comb.apply(lambda row: target_f(row['ql_negbin'], row['ql_tweedie']), axis=1)\n",
    "\n",
    "    def tree_to_code(t, feature_names, ax, xmin, xmax, ymin, ymax, lw=0.5):\n",
    "        tree_ = t.tree_\n",
    "        feature_name = [\n",
    "            feature_names[i] if i != tree._tree.TREE_UNDEFINED else \"undefined!\"\n",
    "            for i in tree_.feature\n",
    "        ]\n",
    "        def recurse(node, depth):\n",
    "            indent = \"  \" * depth\n",
    "            if tree_.feature[node] != tree._tree.TREE_UNDEFINED:\n",
    "                name = feature_name[node]\n",
    "                threshold = tree_.threshold[node]\n",
    "                #print(f\"{indent}if {name} <= {threshold}:\")\n",
    "                if np.where(feature_names == name)[0][0] == 0: # x axis\n",
    "                    ax.vlines(threshold, ymin, ymax, lw=lw, color=\"black\")\n",
    "                    ax.text(threshold, ymax, str(round(threshold,2)), fontsize=6)\n",
    "                else:\n",
    "                    ax.hlines(threshold, xmin, xmax, lw=lw, color=\"black\")\n",
    "                    ax.text(xmax, threshold, str(round(threshold,2)), fontsize=6)\n",
    "                recurse(tree_.children_left[node], depth + 1)\n",
    "                #print(f\"{indent}else:  # if {name} > {threshold}\")\n",
    "                if np.where(feature_names == name)[0][0] == 0: # x axis\n",
    "                    ax.vlines(threshold, ymin, ymax, lw=lw, color=\"black\")\n",
    "                else:\n",
    "                    ax.hlines(threshold, xmin, xmax, lw=lw, color=\"black\")\n",
    "                recurse(tree_.children_right[node], depth + 1)\n",
    "            else:\n",
    "                pass\n",
    "                #print(f\"{indent}return {np.argmax(tree_.value[node])}\")\n",
    "        recurse(0, 0)\n",
    "\n",
    "    for q in comb.q.unique():\n",
    "        #X = comb[comb.q == q].drop(columns=['actual', 'q','ql_negbin','ql_tweedie', 'condw_mean', 'target'])\n",
    "        X = comb[comb.q == q][['adi','cv2']]\n",
    "        #print(X.columns)\n",
    "        Y = comb[comb.q == q]['target']\n",
    "\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=4, min_samples_leaf=int(0.03*len(datasets['test'])))\n",
    "        clf.fit(X, Y)\n",
    "        y_pred = clf.predict(X)\n",
    "\n",
    "        print(\"Accuracy:\", accuracy_score(Y, y_pred))\n",
    "        print(\"Confusion matrix:\\n\", confusion_matrix(Y, y_pred))\n",
    "\n",
    "        def getcolor(x):\n",
    "            if x ==-1: return \"orange\"\n",
    "            if x==0:   return \"green\"\n",
    "            if x==1:   return \"purple\"\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12,clf.get_depth()*3))\n",
    "        p = tree.plot_tree(clf, filled=True, feature_names=X.columns, class_names=[\"negbin\", \"tie\", \"tweedie\"], rounded=True, ax=ax[0])\n",
    "        df = pd.DataFrame(clf.tree_.__getstate__()['nodes'])\n",
    "        leaf_indices = clf.apply(X)\n",
    "        unique_leaf_nodes = np.unique(leaf_indices)\n",
    "        node_sample_indices = {node: np.where(leaf_indices == node)[0] for node in unique_leaf_nodes}\n",
    "        intermittent_leaves = []\n",
    "        for k in node_sample_indices.keys():\n",
    "            tmp = X.iloc[node_sample_indices[k]]\n",
    "            c = {}\n",
    "            c[\"intermittent\"] = np.sum(np.logical_and(tmp.adi >= 1.32, tmp.cv2 <= 0.49))\n",
    "            c[\"smooth\"] = np.sum(np.logical_and(tmp.adi < 1.32, tmp.cv2 <= 0.49))\n",
    "            c[\"erratic\"] = np.sum(np.logical_and(tmp.adi < 1.32, tmp.cv2 > 0.49))\n",
    "            c[\"lumpy\"] = np.sum(np.logical_and(tmp.adi >= 1.32, tmp.cv2 > 0.49))\n",
    "            sorted_c = dict(sorted(c.items(), key=lambda item: item[1], reverse=True))\n",
    "            print(sorted_c)\n",
    "            intermittent_leaves.append(list(sorted_c.keys())[0] == \"intermittent\")\n",
    "        for i in df[df.threshold == -2].index[intermittent_leaves]:\n",
    "            rect = p[np.where(np.array([x.get_bbox_patch() for x in p]) != None)[0][i]].get_bbox_patch()\n",
    "            rect.set_edgecolor(\"red\")\n",
    "            rect.set_linewidth(2)\n",
    "        plt.title(r\"{0}, {1}, {2}\".format(DSET, MODEL, q), fontsize=12)\n",
    "        ax[1].scatter(X.values[:,0], X.values[:,1], c=[getcolor(x) for x in Y.values], s=s, alpha=alpha)\n",
    "        xmin, xmax = np.min(X.values[:,0]), np.max(X.values[:,0])\n",
    "        ymin, ymax = np.min(X.values[:,1]), np.max(X.values[:,1])\n",
    "        tree_to_code(clf, X.columns, ax[1], xmin, xmax, ymin, ymax)\n",
    "        ax[1].axhline(0.49, 0.045, 0.955, c=\"red\", lw=1, ls='--')\n",
    "        ax[1].axvline(1.32, 0, 0.95, c=\"red\", lw=1, ls='--')\n",
    "        ax[1].set_xscale('log')\n",
    "        ax[1].set_yscale('log')\n",
    "        ax[1].set_xlabel(X.columns[0])\n",
    "        ax[1].set_ylabel(X.columns[1])\n",
    "        ax[1].set_xticklabels([])\n",
    "        ax[1].set_yticklabels([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"M5\", MODEL=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"OnlineRetail\", MODEL=\"deepAR\", s=6, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"carparts\", MODEL=\"deepAR\", s=6, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"RAF\", MODEL=\"deepAR\", s=6, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"Auto\", MODEL=\"deepAR\", s=6, alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "its",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
